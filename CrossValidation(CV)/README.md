1ï¸âƒ£ Hold-Out Cross Validation
What it is

The dataset is split only once into two parts:

Training set

Testing set

Steps

Take the full dataset.

Split it into training data (e.g., 70% or 80%).

Use the remaining data (30% or 20%) as test data.

Train the model on the training set.

Evaluate the model on the test set.

Example

Total data = 100 samples

Training = 80 samples

Testing = 20 samples

Advantages

âœ” Very simple
âœ” Fast computation

Disadvantages

âŒ Performance depends on one single split
âŒ Unreliable for small datasets

2ï¸âƒ£ K-Fold Cross Validation
What it is

The dataset is divided into K equal parts (folds).
The model is trained K times.

Steps

Split the dataset into K folds (e.g., K = 5).

Choose one fold as the test set.

Use the remaining Kâˆ’1 folds as the training set.

Train the model and evaluate it.

Repeat steps 2â€“4 until every fold is used once as test data.

Take the average performance of all K runs.

Example (5-Fold)

Fold 1 â†’ test, Fold 2â€“5 â†’ train

Fold 2 â†’ test, Fold 1,3,4,5 â†’ train

â€¦ continue till Fold 5

Advantages

âœ” Better performance estimation
âœ” Uses all data for training and testing

Disadvantages

âŒ More computation than hold-out

3ï¸âƒ£ Leave One-Out Cross Validation (LOOCV)
What it is

A special case of K-Fold where

K = number of data points

Steps

Take one data point as test data.

Use all remaining data points as training data.

Train the model and test it.

Repeat this process for every data point.

Average all results.

Example

If dataset has 100 samples:

1 sample â†’ test

99 samples â†’ train

Total models trained = 100

Advantages

âœ” Uses maximum training data
âœ” Very low bias

Disadvantages

âŒ Extremely slow for large datasets
âŒ High computational cost

4ï¸âƒ£ Stratified K-Fold Cross Validation
What it is

An improved version of K-Fold that maintains class proportion in every fold.

Why needed?

Used when the dataset is imbalanced (one class appears much more than others).

Steps

Divide the dataset into K folds.

Ensure each fold has the same class ratio as the full dataset.

Select one fold as test data.

Use the remaining folds as training data.

Repeat until all folds are used as test data.

Average the results.

Example

Original dataset:

Class A = 90%

Class B = 10%

Each fold will also contain:

~90% Class A

~10% Class B

Advantages

âœ” Reliable for imbalanced datasets
âœ” Better evaluation metrics

Disadvantages

âŒ Not suitable for time-series data

5ï¸âƒ£ Monte Carlo Cross Validation (Random Sampling)
What it is

The dataset is randomly split multiple times into training and testing sets.

Steps

Randomly split the dataset into training and test sets.

Train the model and evaluate it.

Repeat the random split many times.

Calculate the average performance.

Example

Train = 80%, Test = 20%

Repeat this random split 20â€“50 times

Run 1 â†’ random 20% test
Run 2 â†’ another random 20% test
Run 3 â†’ again random 20% test
...
...
...

Advantages

âœ” Flexible train-test sizes
âœ” More robust than single hold-out

Disadvantages

âŒ Some samples may never be tested
âŒ Results vary if random seed not fixed

ğŸ”‘ Summary Table
Method	Main Idea	Best Use Case
Hold-Out	One split	Large datasets
K-Fold	K equal splits	General ML problems
LOOCV	One sample test	Very small datasets
Stratified K-Fold	Balanced folds	Imbalanced datasets
Monte Carlo	Random splits	Flexible evaluation